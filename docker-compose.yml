services:
  api:
    build: .
    ports:
      - "8000:8000"
    env_file:
      - .env
    environment:
      MLFLOW_TRACKING_URI: ${MLFLOW_TRACKING_URI:-http://mlflow:5000}
      MLFLOW_EXPERIMENT_NAME: ${MLFLOW_EXPERIMENT_NAME:-ai-scrum-copilot-mvp}
    depends_on:
      - mlflow
    volumes:
      - ./backend:/app/backend
      - ./data:/app/data
      - ./data/mlflow:/mlflow
      - ./app.db:/app/app.db

  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.12.2
    command: >
      mlflow server
      --host 0.0.0.0
      --port 5000
      --backend-store-uri sqlite:////mlflow/mlflow.db
      --default-artifact-root /mlflow/artifacts
      --serve-artifacts
      --artifacts-destination /mlflow/artifacts
    ports:
      - "5000:5000"
    volumes:
      - ./data/mlflow:/mlflow

  frontend:
    build:
      context: ./frontend
      args:
        VITE_API_URL: ${VITE_FRONTEND_API_URL:-/api}
        VITE_APP_PROFILE: ${APP_PROFILE:-prod}
        VITE_AZURE_AD_CLIENT_ID: ${VITE_AZURE_AD_CLIENT_ID:-}
        VITE_AZURE_AD_TENANT_ID: ${VITE_AZURE_AD_TENANT_ID:-}
        VITE_AZURE_AD_SCOPES: ${VITE_AZURE_AD_SCOPES:-}
    ports:
      - "4173:4173"
    depends_on:
      - api

  worker:
    build: .
    command: [ "python", "-m", "backend.worker" ]
    env_file:
      - .env
    environment:
      MLFLOW_TRACKING_URI: ${MLFLOW_TRACKING_URI:-http://mlflow:5000}
      MLFLOW_EXPERIMENT_NAME: ${MLFLOW_EXPERIMENT_NAME:-ai-scrum-copilot-mvp}
    depends_on:
      - api
